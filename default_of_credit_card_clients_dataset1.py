# -*- coding: utf-8 -*-
"""default of credit card clients dataset1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J97D8eRffCaQdBg0kmpxlOF3aUAHbsAF

**Introduction**

This notebook was created for analysis and prediction making of the Default of credit card clients Data Set from UCI Machine Learning Library.

**Attribute Information**
Below there are the description of the attributes that will be used in our model for better understanding of the data:

LIMIT_BAL: Amount of the given credit (NT dollar). It includes both the individual consumer credit and his/her family (supplementary) credit.

SEX: Gender (1 = male; 2 = female).

EDUCATION: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).

MARRIAGE: Marital status (1 = married; 2 = single; 3 = others).
AGE: Age (year).

PAY_1: the repayment status in September, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.

PAY_2: the repayment status in August, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.

PAY_3: the repayment status in July, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.

PAY_4: the repayment status in June, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.

PAY_5: the repayment status in May, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.

PAY_6: the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.

BILL_AMT1: Amount of bill statement (NT dollar). Amount of bill statement in September, 2005.

BILL_AMT2: Amount of bill statement (NT dollar). Amount of bill statement in August, 2005.

BILL_AMT3: Amount of bill statement (NT dollar). Amount of bill statement in July, 2005.

BILL_AMT4: Amount of bill statement (NT dollar). Amount of bill statement in June, 2005.

BILL_AMT5: Amount of bill statement (NT dollar). Amount of bill statement in May, 2005.

BILL_AMT6: Amount of bill statement (NT dollar). Amount of bill statement in April, 2005.

PAY_AMT1: Amount of previous payment (NT dollar). Amount paid in September, 2005.
PAY_AMT2: Amount of previous payment (NT dollar). Amount paid in August, 2005.

PAY_AMT3: Amount of previous payment (NT dollar). Amount paid in July, 2005.

PAY_AMT4: Amount of previous payment (NT dollar). Amount paid in June, 2005.
PAY_AMT5: Amount of previous payment (NT dollar). Amount paid in May, 2005.
PAY_AMT6: Amount of previous payment (NT dollar). Amount paid in June, 2005.

dpnm: Default payment next month.(Yes = 1, No = 0)

**Models¶**

I  create 2 models in order to make predictions and compare them with the original paper. These models are:

Logistic Regression
Decision tree


# Goal¶
Using the models we created, we will try to predict the class value of dpnm column with better scores (accuracy and f1)

### **import libarires**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
#lm models
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn import tree
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
#matrecis
from sklearn import metrics
from sklearn.metrics import f1_score,confusion_matrix, precision_score, recall_score

"""**load data**"""

df=pd.read_csv("/content/default of credit card clients.csv")
df

"""## **EDA **"""

df.head()

df.info
display(df.info())

df.describe
display(df.describe())

print(df["MARRIAGE"].value_counts())
print(df["EDUCATION"].value_counts())

df["MARRIAGE"]=df["MARRIAGE"].replace(0,3)
df["EDUCATION"]=df["EDUCATION"].replace([0,5,6],4)
print (df["MARRIAGE"].value_counts())
print (df["EDUCATION"].value_counts())

df.isnull().sum()

print(df.duplicated().sum())

df.drop_duplicates(inplace=True)
df

plt.figure(figsize=(20,20))
sns.heatmap(df.corr(),annot=True,cmap='rainbow',linewidth=0.5,fmt='.2f')
plt.show()

sns.countplot(x='dpnm', data=df)
plt.title('Distribution of Target Variable (dpnm)')
plt.xlabel('Default (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

sns.boxplot(x=df['LIMIT_BAL'])
plt.title('Boxplot of LIMIT_BAL')
plt.xlabel('LIMIT_BAL')
plt.show()

sns.countplot(x='SEX', hue='dpnm', data=df)
plt.title('Sex vs Default')
plt.xlabel('Sex (1 = Male, 2 = Female)')
plt.ylabel('Count')
plt.legend(title='Default')
plt.show()

"""**preprocessing**

In this part we prepare our data for our models. This means that we choose the columns that will be our independed variables and which column the class that we want to predict. Once we are done with that, we split our data into train and test sets and perfom a standardization upon them.

dbmn="default payment next month"


"""

X= df[df.columns[:-1]]
y= df['dpnm']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=25)

scaler=StandardScaler()
x_train_scaled=scaler.fit_transform(X_train)
x_test_scaled=scaler.transform(X_test)

""" Modeling

In this section we build and try 2 models:

Logistic Regression &

Decision tree
"""

logreg=LogisticRegression(multi_class='auto', random_state=25, n_jobs=-1)
print(logreg.fit(X_train,y_train))

log_pred=logreg.predict(X_test)
logreg_cv=cross_val_score(logreg, X_train, y_train, cv=10).mean()

print('Accuracy: %.3f' % logreg.score(X_test, y_test))
print('Cross-validation accuracy: %0.3f' % logreg_cv)
print('Precision: %.3f' % precision_score(y_test, log_pred))
print('Recall: %.3f' % recall_score(y_test, log_pred))
print('F1 score: %.3f' % f1_score(y_test, log_pred))

"""Dession tree"""

tr = tree.DecisionTreeClassifier(max_depth=3, criterion='gini', random_state=25)
tr.fit(X_train, y_train)

fig=plt.figure(figsize=(23,15))
tree.plot_tree(tr.fit(X_train, y_train),feature_names=X.columns,filled=True,rounded=True,fontsize=16);
plt.title('Decision Tree');